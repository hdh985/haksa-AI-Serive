import os
from dotenv import load_dotenv

# âœ… LangChain 0.2+ ë²„ì „ìš© import
from langchain_community.document_loaders import PyPDFLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.embeddings import OpenAIEmbeddings
from langchain_community.vectorstores import Chroma

load_dotenv()
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")

def build_vector_db():
    print("ğŸ“„ PDF ë¡œë“œ ì¤‘...")

    # âœ… ê²½ë¡œë¥¼ ì ˆëŒ€ê²½ë¡œ ê¸°ë°˜ìœ¼ë¡œ ì•ˆì „í•˜ê²Œ ì²˜ë¦¬
    base_dir = os.path.dirname(os.path.abspath(__file__))
    pdf_path = os.path.join(base_dir, "data", "Haksa.pdf")
    db_dir = os.path.join(base_dir, "db", "chroma_db")

    if not os.path.exists(pdf_path):
        raise FileNotFoundError(f"âŒ PDF íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {pdf_path}")

    loader = PyPDFLoader(pdf_path)
    documents = loader.load()

    print("âœ‚ï¸ í…ìŠ¤íŠ¸ ë¶„ë¦¬ ì¤‘...")
    splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)
    chunks = splitter.split_documents(documents)

    print("ğŸ§  ì„ë² ë”© ìƒì„± ì¤‘...")
    embedding = OpenAIEmbeddings(model="text-embedding-3-small")

    print("ğŸ’¾ ë²¡í„°DB ì €ì¥ ì¤‘...")
    vectordb = Chroma.from_documents(
        documents=chunks,
        embedding=embedding,
        persist_directory=db_dir
    )
    vectordb.persist()

    print(f"âœ… í•™ìŠµ ì™„ë£Œ! DB ìƒì„±ë¨: {db_dir}")

if __name__ == "__main__":
    build_vector_db()
